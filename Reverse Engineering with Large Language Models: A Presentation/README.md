Project Overview
This repository contains a group presentation on the paper titled "Pop Quiz! Can a Large Language Model Help With Reverse Engineering?".
The presentation was created as part of a collaborative effort to explore the capabilities of large language models, specifically OpenAI's Codex, in the context of reverse engineering.

Abstract
The referenced paper investigates the potential of large language models (LLMs) like OpenAI's Codex to assist with reverse engineering tasks. The study focuses on the model's ability to identify the purpose, capabilities, and important variable names or values from decompiled code through zero-shot multi-tasking. By prompting Codex with open-ended questions and employing a true/false quiz framework, the researchers conducted a comprehensive quantitative analysis. Out of 136,260 questions posed, Codex answered 72,754 correctly. The findings suggest that while LLMs show promise, they are not yet fully capable of zero-shot reverse engineering.

Contents
PowerPoint Presentation: The slides used by our group to present the findings and insights from the paper.
Research Paper PDF: The original research paper that our presentation is based on.
Purpose
The purpose of this repository is to share the presentation and provide access to the original research paper. This project aims to disseminate knowledge about the capabilities and limitations of large language models in the context of reverse engineering, as explored in the referenced study.

Usage
Feel free to explore the PowerPoint presentation to gain insights into the study's findings and methodology. The accompanying PDF of the research paper provides a detailed account of the experiments and results discussed in our presentation.

Acknowledgments
The research paper, "Pop Quiz! Can a Large Language Model Help With Reverse Engineering?", was not authored by our group. We used the paper to create our presentation and analyze the potential of large language models in reverse engineering.
